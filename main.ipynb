{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convirtiendo datos a ttl\n",
    ":D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # no quitar, se rompe el proyectoimport pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL inválida, debe comenzar con 'https://'\n",
      "Código de Wikidata: None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "ISDEBUG = False\n",
    "\n",
    "def obtener_codigo_wikidata(url):\n",
    "\n",
    "    if ISDEBUG:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Extraer el título del artículo de la URL\n",
    "        if not url.startswith(\"http://\" or \"https://\"):\n",
    "            raise Exception(\"URL inválida, debe comenzar con 'https://'\")\n",
    "\n",
    "        title = url.split(\"/wiki/\")[-1]\n",
    "        if not title:\n",
    "            raise Exception(\"No se encontró el título del artículo en la URL proporcionada.\")\n",
    "\n",
    "        # Llamar a la API de MediaWiki para obtener datos de la entidad\n",
    "        endpoint = \"https://en.wikipedia.org/w/api.php\"\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"pageprops\",\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        # Extraer el código de Wikidata\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "        for page_id, page_info in pages.items():\n",
    "            if \"pageprops\" in page_info and \"wikibase_item\" in page_info[\"pageprops\"]:\n",
    "                return page_info[\"pageprops\"][\"wikibase_item\"]\n",
    "\n",
    "        raise Exception(\"No se encontró el código de Wikidata para la URL proporcionada.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error al obtener los datos de Wikidata: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso\n",
    "url = \"https://en.wikipedia.org/wiki/Max_Verstappen\"\n",
    "codigo_wikidata = obtener_codigo_wikidata(url)\n",
    "print(f\"Código de Wikidata: {codigo_wikidata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos TODO PORQUE SI\n",
    "circuits = pd.read_csv('data/circuits.csv')\n",
    "constructorResults = pd.read_csv('data/constructor_results.csv')\n",
    "constructors = pd.read_csv('data/constructors.csv')\n",
    "constructorStandings = pd.read_csv('data/constructor_standings.csv')\n",
    "drivers = pd.read_csv('data/drivers.csv')\n",
    "driverStandings = pd.read_csv('data/driver_standings.csv')\n",
    "lapTimes = pd.read_csv('data/lap_times.csv')\n",
    "pitStops = pd.read_csv('data/pit_stops.csv')\n",
    "qualifying = pd.read_csv('data/qualifying.csv')\n",
    "races = pd.read_csv('data/races.csv')\n",
    "races_results = pd.read_csv('data/results.csv')\n",
    "seasons = pd.read_csv('data/seasons.csv')\n",
    "NAME_FILE = \"data.ttl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nueva, notacion usando las siguientes data classes, esta para \n",
      "1 mantener la ontologia limpia es decir no tener duplicas de definicion de algo \n",
      "2 hacer un solo flush en el archivo ttl los datos, lo que implicara una mejora en el tiempo de la generacion del archivo\n"
     ]
    }
   ],
   "source": [
    "print(\"nueva, notacion usando las siguientes data classes, esta para \\n1 mantener la ontologia limpia es decir no tener duplicas de definicion de algo \\n2 hacer un solo flush en el archivo ttl los datos, lo que implicara una mejora en el tiempo de la generacion del archivo\")\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Union, Dict\n",
    "\n",
    "@dataclass\n",
    "class RDFPredicate:\n",
    "    property: str\n",
    "    objects: List[str]\n",
    "\n",
    "@dataclass\n",
    "class RDFStatement:\n",
    "    _instances = {}\n",
    "    subject: str\n",
    "    predicates: dict[str, list[str]] = field(default_factory=dict)\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        # subject expected to either be the first args or with the key \"subject\"\n",
    "        subject = kwargs.get(\"subject\", args[0] if args else None)\n",
    "\n",
    "        if not subject:\n",
    "            raise ValueError(\"RDFStatement requires a 'subject' argument.\")\n",
    "    \n",
    "        if subject not in cls._instances:\n",
    "            new_instance = super(RDFStatement, cls).__new__(cls)\n",
    "            new_instance.subject = subject\n",
    "            new_instance.predicates = {}\n",
    "            cls._instances[subject] = new_instance\n",
    "        \n",
    "        return cls._instances[subject]\n",
    "\n",
    "    def __init__(self, subject: str, predicate: Union[str, RDFPredicate, List[RDFPredicate], List[List[any]]] = None, objects: Union[str, List[str]] = None):\n",
    "        if predicate is None and objects is None:\n",
    "            return\n",
    "        \n",
    "        elif (all(isinstance(p, list) for p in predicate)):\n",
    "            for p in predicate:\n",
    "                self._insert_statement(p[0], p[1])\n",
    "        \n",
    "        else:\n",
    "            self._insert_statement(predicate, objects)\n",
    "\n",
    "    def _insert_statement(self, predicate: Union[str, RDFPredicate, List[RDFPredicate], List[List[RDFPredicate]]]= None, objects: Union[str, List[str]] = None):\n",
    "        if isinstance(predicate, str):\n",
    "            is_objects_str = isinstance(objects, str)\n",
    "            if not (is_objects_str or all(isinstance(o, str) for o in objects)):\n",
    "                raise Exception(f\"RDFStatement: {type(objects)} expected Union[str, List[str]]\")\n",
    "            if is_objects_str:\n",
    "                objects = [objects]\n",
    "            self._insert_on_property(predicate, objects)\n",
    "        \n",
    "        elif isinstance(predicate, RDFPredicate):\n",
    "            self._insert_on_property(predicate.property, predicate.objects)\n",
    "\n",
    "        elif isinstance(predicate, list):\n",
    "            if not all(isinstance(p, RDFPredicate) for p in predicate):\n",
    "                raise Exception(f\"RDFStatement: {type(predicate)=} expected List[RDFPredicate]\")\n",
    "            for rdfp in predicate:\n",
    "                self._insert_on_property(rdfp.property, rdfp.objects)\n",
    "        elif predicate is None and objects is None:\n",
    "            return\n",
    "        else:\n",
    "            raise Exception(f\"RDFStatement:{predicate} {type(predicate)=} expected Union[str, RDFPredicate, List[RDFPredicate]]\")\n",
    "        \n",
    "    def _insert_on_property(self, property: str, objects: list[str]):\n",
    "        error = [\"a\", \"rdf:type\", \"rdfs:type\"]\n",
    "        if property in error:\n",
    "            if any(e in self.predicates.keys() for e in error):\n",
    "                print(f\"RDFStatement: Redefinition of a object type. {self} intended to overwrite {property} with {objects}\")\n",
    "                # raise Exception(f\"RDFStatement: Redefinition of a object type.\")\n",
    "        if property in self.predicates:\n",
    "            for obj in objects:\n",
    "                if obj not in self.predicates[property]:\n",
    "                    self.predicates[property].append(obj)\n",
    "        else:\n",
    "            self.predicates[property] = objects\n",
    "    \n",
    "    def to_ttl(self) -> str:\n",
    "        ret = self.subject + \" \"\n",
    "        for property, objects in self.predicates.items():\n",
    "            ret += property + \" \" + \", \".join(objects) + \";\\n\\t\"\n",
    "        ret = ret[:-3]\n",
    "        ret += \".\"\n",
    "        return ret\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return id(self)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, RDFStatement):\n",
    "            return self.__hash__() == other.__hash__()\n",
    "        return False\n",
    "    \n",
    "class OrderSet:\n",
    "    def __init__(self):\n",
    "        self.data = {} \n",
    "\n",
    "    def insert(self, element):\n",
    "        if element not in self.data:\n",
    "            self.data[element] = len(self.data)\n",
    "\n",
    "    def get_yield(self):\n",
    "        # Devolver los elementos con su orden de inserción\n",
    "        for element, order in self.data.items():\n",
    "            yield (order, element)\n",
    "\n",
    "ontology = OrderSet()\n",
    "subjects = OrderSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ej 1:\n",
    "```ttl\n",
    ":11 a rdfs:Class;\n",
    "\t:famosoPor \"numero chistoso\"@es, \"es primo\"@es.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":11 a rdfs:Class;\n",
      "\t:famosoPor \"numero chistoso\"@es, \"es primo\"@es.\n"
     ]
    }
   ],
   "source": [
    "RDFStatement(\":11\", \"a\", \"rdfs:Class\")\n",
    "RDFStatement(\":11\", \":famosoPor\", ['\"numero chistoso\"@es', '\"es primo\"@es'])\n",
    "print(RDFStatement(\":11\").to_ttl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def ttl_format(input_str: str) -> str:\n",
    "    input_str = ''.join(c for c in unicodedata.normalize('NFKD', input_str) if not unicodedata.combining(c))\n",
    "    input_str = input_str.lower().title().replace(\" \", \"_\")\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar RDF Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: HACER LA WEA\n",
    "ontology.insert(RDFStatement(\"f1:Nationality\", [[\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "                                            [\"rdfs:label\", \"'A F1 nationality'@en\"],\n",
    "                                            [\"rdfs:comment\", \"'A class representing a nationality related to F1'@en\"]]))\n",
    "\n",
    "unique_nationality = drivers['nationality'].unique()\n",
    "\n",
    "i = 0 \n",
    "for nationality in unique_nationality:\n",
    "    if i > 10:\n",
    "        break\n",
    "    subjects.insert(RDFStatement(f\"f1:{ttl_format(nationality)}\", [\n",
    "        [\"a\", \"f1:Nationality\"],\n",
    "        [\"rdfs:label\", f\"'{nationality}'@en\"]\n",
    "    ]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar RDF Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró el código de Wikidata para la URL proporcionada.\n",
      "No se encontró el código de Wikidata para la URL proporcionada.\n"
     ]
    }
   ],
   "source": [
    "# Tenemos las nacionalidades de los pilotos, ahora crearemos el resto de datos\n",
    "\n",
    "# Creamos la clase f1 Driver\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:Driver\", [\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:label\", \"'A F1 Driver'@en\"],\n",
    "    [\"rdfs:comment\", \"'A class representing a F1 driver'@en\"]\n",
    "]))\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:Code\", [\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:label\", \"'A F1 Short 3 letter display'@en\"],\n",
    "    [\"rdfs:comment\", \"'The usual way to represent a competitor in a race'@en\"]\n",
    "]))\n",
    "\n",
    "# Añadimos cada driver con su nacionalidad correspondiente:\n",
    "# Por cada driver, añadimos su nombre, su fecha de nacimiento, su nacionalidad y su número de piloto\n",
    "\n",
    "#Muchos drivers number son simplemente /N, eliminar?\n",
    "driver = []\n",
    "i = 0\n",
    "driver_ref = {}\n",
    "for index, row in drivers.iterrows():\n",
    "    if i > 10 : break\n",
    "\n",
    "    if ttl_format(row['driverRef']) == \"Driver\":\n",
    "        continue\n",
    "    \n",
    "    wikidata_code = obtener_codigo_wikidata(row[\"url\"])\n",
    "    \n",
    "    driver_ref[row['driverId']] = row['driverRef']\n",
    "    driver.append(RDFStatement(f\"f1:{ttl_format(row['driverRef'])}\", [\n",
    "        [\"a\", \"f1:Driver\"],\n",
    "        [\"rdfs:label\", f'\"{row['forename']} {row['surname']}\"@en'],\n",
    "        [\"f1:Nationality\",f\"f1:{ttl_format(row['nationality'])}\"],\n",
    "        [\"f1:dateOfBirth\", f\"'{row['dob']}'^^xsd:date\"],\n",
    "    ]))\n",
    "\n",
    "    if wikidata_code:\n",
    "        RDFStatement(f\"f1:{ttl_format(row['driverRef'])}\", \"owl:sameAs\", f\"wd:{wikidata_code}\")\n",
    "\n",
    "    if row['code'] != r'\\N':\n",
    "        RDFStatement(f\"f1:{ttl_format(row['driverRef'])}\", \"f1:Code\", f\"'{row['code']}'\")\n",
    "        \n",
    "    i += 1 \n",
    "\n",
    "for d in driver:\n",
    "    subjects.insert(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar RDF Pistas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ttl\n",
    "f1:Circuit a rdf:Class, owl:Class;\n",
    "    rdfs:label 'A F1 Circuit'@en;\n",
    "    rdfs:comment 'A class representing a F1 circuit'@en.\n",
    "\n",
    "f1:City a rdf:Class, owl:Class;\n",
    "    rdfs:label 'A City'@en;\n",
    "    rdfs:comment 'A City in the world related to f1'@en.\n",
    "\n",
    "f1:hostCity a rdf:Property;\n",
    "    rdfs:label 'City'@en;\n",
    "    rdfs:comment 'a City hosting a F1 circuit'@en;\n",
    "    rdfs:domain f1:Circuit.\n",
    "\n",
    "f1:hostCountry a rdf:Property;\n",
    "    rdfs:label 'Country'@en;\n",
    "    rdfs:comment 'a Country hosting a F1 circuit'@en;\n",
    "    rdfs:domain f1:Circuit.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology.insert(RDFStatement(\"f1:Circuit\", [[\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "                                            [\"rdfs:label\", \"'A F1 Circuit'@en\"],\n",
    "                                            [\"rdfs:comment\", \"'A class representing a F1 circuit'@en\"]]))\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:Country\", [[\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "                                            [\"rdfs:label\", \"'A F1 Country'@en\"],\n",
    "                                            [\"rdfs:comment\", \"'A class representing a F1 country'@en\"]]))\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:City\",[[\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "                                        [\"rdfs:label\", \"'A City'@en\"],\n",
    "                                        [\"rdfs:comment\", \"'A City in the world related to f1'@en;\"]]))\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:hostCity\",[[\"a\", \"rdf:Property\"],\n",
    "                                            [\"rdfs:label\", \"'City'@en\"],\n",
    "                                            [\"rdfs:comment\", \"'a City hosting a F1 circuit'@en\"],\n",
    "                                            [\"rdfs:domain\", \"f1:Circuit\"]]))\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:hostCountry\", [[\"a\", \"rdf:Property\"],\n",
    "                                                [\"rdfs:label\", \"'Country'@en\"],\n",
    "                                                [\"rdfs:comment\", \"'a Country hosting a F1 circuit'@en\"],\n",
    "                                                [\"rdfs:domain\", \"f1:Circuit\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example:\n",
    "```ttl\n",
    "f1:albert_park a f1:Circuit;\n",
    "    rdfs:label 'Albert Park Grand Prix Circuit'@en;\n",
    "    f1:hostCity f1:Melbourne;\n",
    "    f1:hostCountry f1:Australia;\n",
    "    geo:lat \"-37.8497\"^^xsd:float;\n",
    "    geo:long \"144.968\"^^xsd:float;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "countries = []\n",
    "sub1 = []\n",
    "sub2 = []\n",
    "circuits_ref = {}\n",
    "\n",
    "i = 0\n",
    "for index, row in circuits.iterrows():\n",
    "    #if i > 10: break\n",
    "    circuits_ref[row[\"circuitId\"]] = f\"{row[\"circuitRef\"]}_Circuit\"\n",
    "\n",
    "    circuit = f\"f1:{ttl_format(row[\"circuitRef\"])}_Circuit\"\n",
    "    wkdta = obtener_codigo_wikidata(row[\"url\"])\n",
    "\n",
    "    sub2.append(\n",
    "        RDFStatement(\n",
    "            circuit,\n",
    "            [\n",
    "                [\"rdf:type\", \"f1:Circuit\"],\n",
    "                [\"rdfs:label\", f\"'{row[\"name\"]}'@en\"],\n",
    "                [\"f1:hostCity\", f\"f1:{ttl_format(row[\"location\"])}\"],\n",
    "                [\"f1:hostCountry\", f\"f1:{ttl_format(row[\"country\"])}\"],\n",
    "                [\"geo:lat\", f'\"{row[\"lat\"]}\"^^xsd:float'],\n",
    "                [\"geo:long\", f'\"{row[\"lng\"]}\"^^xsd:float']\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    cities.append(ttl_format(row[\"location\"]))\n",
    "    countries.append(ttl_format(row[\"country\"]))\n",
    "\n",
    "    if wkdta:\n",
    "        RDFStatement(circuit, \"owl:sameAs\", f\"wd:{wkdta}\")\n",
    "\n",
    "cities = list(set(cities))\n",
    "for city in cities:\n",
    "    sub1.append(RDFStatement(f\"f1:{city}\", \"a\", \"f1:City\"))\n",
    "\n",
    "countries = list(set(countries))\n",
    "for country in countries:\n",
    "    sub1.append(RDFStatement(f\"f1:{country}\", \"a\", \"f1:Country\"))\n",
    "\n",
    "for i in sub1:\n",
    "    subjects.insert(i)\n",
    "\n",
    "for i in sub2:\n",
    "    subjects.insert(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar RDF Constructores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology.insert(RDFStatement(\"f1:Constructor\", [\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:comment\", \"'A class representing an F1 constructor'@en\"]\n",
    "    ]))\n",
    "\n",
    "i = 0\n",
    "constructors_RDFS = []\n",
    "constructors_ref = {}\n",
    "for index,row in constructors.iterrows():\n",
    "    #if i > 10: break\n",
    "    constructors_ref[row[\"constructorId\"]] = row[\"constructorRef\"]\n",
    "    constructors_RDFS.append(RDFStatement(f\"f1:{ttl_format(row['constructorRef'])}_Constructor\", [\n",
    "        [\"a\", \"f1:Constructor\"],\n",
    "        [\"rdfs:label\", f\"'{row['name']}'@en\"],\n",
    "        [\"f1:Nationality\", f\"f1:{row[\"nationality\"].replace(\" \", \"_\")}\"]\n",
    "        ]))\n",
    "    i+=1\n",
    "\n",
    "for c in constructors_RDFS:\n",
    "    subjects.insert(c)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_data = []\n",
    "\n",
    "ontology.insert(RDFStatement(\"f1:Season\", [\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:comment\", \"'A class representing a F1 season'@en\"]\n",
    "    ]))\n",
    "\n",
    "for index, row in seasons.iterrows():\n",
    "    seasons_data.append(RDFStatement(f\"f1:{row['year']}_Season\", [\n",
    "        [\"a\", \"f1:Season\"],\n",
    "        [\"rdfs:label\", f\"'{row['year']}'@en\"]\n",
    "    ]))\n",
    "    \n",
    "for s in seasons_data:\n",
    "    subjects.insert(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carreras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_id = {}\n",
    "\n",
    "ontology.insert(RDFStatement(f\"f1:Race\",[\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:comment\", \"'A class representing'@en\"]\n",
    "]))\n",
    "\n",
    "i=0\n",
    "races_data = []\n",
    "races_ref = {}\n",
    "for index, row in races.iterrows():\n",
    "    #if i > 0: break\n",
    "    races_ref[row['raceId']] = f\"{row['year']}_{row['round']}\"\n",
    "    races_data.append(RDFStatement(f\"f1:{row['year']}_{row['round']}\", [\n",
    "        [\"a\", \"f1:Race\"],\n",
    "        [\"f1:circuit\", f\"f1:{ttl_format(circuits_ref[row['circuitId']])}\"],\n",
    "        [\"f1:date\", f\"'{row['date']}'^^xsd:date\"],\n",
    "        [\"f1:round\", f\"'{row['round']}'^^xsd:integer\"],\n",
    "        [\"f1:year\", f\"'{row['year']}'^^xsd:integer\"],\n",
    "        [\"f1:season\", f\"f1:{row['year']}_Season\"]\n",
    "    ]))\n",
    "    if row['time'] != r'\\N':\n",
    "        races_data.append(RDFStatement(f\"f1:{row['year']}_{row['round']}\", \"f1:time\", f\"'{row['time']}'^^xsd:time\"))\n",
    "    if row['url'] != r'\\N':\n",
    "        races_data.append(RDFStatement(f\"f1:{row['year']}_{row['round']}\", \"f1:url\", f\"'{row['url']}'\"))\n",
    "    i += 1\n",
    "\n",
    "for i in races_data:\n",
    "    subjects.insert(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ESTO SE HIZO TAN SOLO PARA RESERVAR EL ESPACIO, SE REVISARA EL ARCHIVO result.csv\n",
    "data_results = []\n",
    "ontology.insert(RDFStatement(\"f1:Result\", [\n",
    "    [\"a\", [\"rdf:Class\", \"owl:Class\"]],\n",
    "    [\"rdfs:comment\", \"'A class representing a F1 result about a races'@en\"]\n",
    "]))\n",
    "\n",
    "for index, row in races_results.iterrows():\n",
    "    if row['driverId'] not in driver_ref.keys():\n",
    "        continue\n",
    "    \n",
    "    if row['constructorId'] not in constructors_ref.keys():\n",
    "        continue\n",
    "    \n",
    "    if r\"\\N\" == row[\"position\"]:\n",
    "        continue\n",
    "    \n",
    "    data_results.append(RDFStatement(f\"f1:{row['raceId']}_{row[\"position\"]}\", [\n",
    "        [\"a\", \"f1:Result\"],\n",
    "        [\"f1:races\", f\"f1:{races_ref[row['raceId']]}\"],\n",
    "        [\"f1:driver\", f\"f1:{driver_ref[row['driverId']]}\"],\n",
    "        [\"f1:position\", f\"'{row['position']}'^^xsd:integer\" if r\"\\N\" != row[\"position\"] else \"'No_Positioned'\"],\n",
    "        [\"f1:points\", f\"'{row['points']}'^^xsd:float\"],\n",
    "        [\"f1:counstructor\", f\"f1:{constructors_ref[row['constructorId']]}\"],\n",
    "        [\"f1:time\", f\"'{row['time']}'\" if r\"\\N\" != row[\"time\"] else \"'No_Time'\"]\n",
    "        ]))\n",
    "    \n",
    "    \n",
    "for i in data_results:\n",
    "    subjects.insert(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escritura de ontologia y subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NAME_FILE, 'w') as f:\n",
    "    f.write(\"\"\"@prefix f1: <http://ex.org/f1#>.\n",
    "@prefix geo:  <http://www.opengis.net/ont/geosparql#>.\n",
    "@prefix wd: <http://www.wikidata.org/entity/>.\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>.\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>. \n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#>.\\n\\n\"\"\")\n",
    "\n",
    "    l = list(ontology.get_yield())\n",
    "    l.sort()\n",
    "    for e in l:\n",
    "        f.write(e[1].to_ttl() + \"\\n\\n\")\n",
    "\n",
    "    l = list(subjects.get_yield())\n",
    "    l.sort()\n",
    "    for e in l:\n",
    "        f.write(e[1].to_ttl() + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
